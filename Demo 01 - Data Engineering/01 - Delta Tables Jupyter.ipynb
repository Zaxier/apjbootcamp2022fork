{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo based on APJ Bootcamp flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Delta Tables.py\n",
    "\n",
    "- Load data from **Databricks Unity Catalog** Metastore\n",
    "  - What is Unity Catalog? (What are the component parts? [metastore, catalog, ... ])\n",
    "  - What is Delta Lake\n",
    "- Create a Delta Lake table based off some data made available to me from the Unity Catalog Metastore\n",
    "- Run Delta Table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been told by my organisation that there's data available for me to start doing work on in Catalog\n",
    "\n",
    "`xaorg_dev` and what about `xaorg_prod` and `xaorg_staging`?\n",
    "\n",
    "What is in this catalog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great I have a database here for me to work with\n",
    "Idea have a database for the sales data and a database for my personal sandbox\n",
    "\n",
    "Link to another notebook if they want to see exactly how the data got to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now I want to manipulate my data in a more flexible way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show loading 2 tables into dataframes in PySpark, one small one big.\n",
    "- \"I can do really interesting things with datasets large and small\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about showing them the lineage of a data set early'ish because then we can bring up trust in the data. \n",
    "\n",
    "Where is all this data coming from? I don't trust it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to a live real-time model inference endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhere above, our flow should be show the DLT dag just to show where the data is coming from and don't go into details and then after covering Data Science/ML + DBSQL then circle back around to the thing you showed earlier... the data engineering.\n",
    "\n",
    "So map is\n",
    "- **Lakehouse** \"Serve that data up on a platter\"\n",
    "  - Show how you have interact with data with SQL\n",
    "  - Show table display\n",
    "  - Show creation of a visualisation with UI\n",
    "- **Notebook experience**\n",
    "  - Show access to governed data (Unity Catalog, Data Explorer)\n",
    "  - Show that you can do more complex transformations with Python\n",
    "  - Show that you can easily access or install open-source libraries (More general)\n",
    "  - Show that you can create visualisations with matplotlib/seaborn\n",
    "- **DataOps and Data Engineering**\n",
    "  - Show that you're working with the freshest data with a 1-minute refresh rate (Leads to Workflows, DLT, Streaming)\n",
    "  - Show that you can ***trust*** the data with data lineage (UC) and jobs lineage.\n",
    "    - Screenshot - https://drive.google.com/file/d/1TzF6biRauYHbo2SriW-4A1T5l-nNycSy/view\n",
    "    - Screenshot - https://drive.google.com/file/d/1tH0vmqBP48GvikEU6-l-osVToXzdckQe/view\n",
    "  - Explain how as an analyst I may not know how to write streaming data pipelines, however knowing SQL and looking at this code, I think this is something I could learn quite quickly.\n",
    "- **Machine Learning**\n",
    "  - Show how to do ***feature engineering*** on big data sets with spark or pandas_on_spark --> Feature store pulls from silver and loads ML specific, transformed and (hopefully) normalised features.\n",
    "  - \n",
    "  - Let's engineer some features\n",
    "  - Let's use AutoML to find out what features are most predictive of orange quality, to decide where to spend investment in chemistry and genetic engineering.\n",
    "  - Use the UI and use the python api.\n",
    "  - MLflow tracking\n",
    "  - Mlflow model registry\n",
    "  - MLflow model deployment - Batch/real-time\n",
    "    - Link to running real-time API\n",
    "- **Optimisation** (bit out-there)\n",
    "  - They can't control xxx, however they can control A and B which happens to be predictive factors of xxxx, \n",
    "    - what's the best pairing of A and B?\n",
    "    - what are the distributions of A and B for high-qual oranges, what about for low-qual oranges\n",
    "- What about BI?\n",
    "  - DBSQL, query and dashboards \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lakehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lets serve that data up on a platter:  ----->  '-_____-'\n"
     ]
    }
   ],
   "source": [
    "# LAKEHOUSE\n",
    "'''\n",
    "    THE GOAL:\n",
    "    Show how easy it is to access data in your lakehouse.\n",
    "    The scenario is that you've been given access to Databricks\n",
    "    \n",
    "    WHAT HAPPENED?:\n",
    "    In the end we end up accessing data and more...\n",
    "        i.e. we ended up doing some EDA without even really trying.\n",
    "\n",
    "'''\n",
    "\n",
    "print(\"Lets serve that data up on a platter:  ----->  '-_____-'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Show contents of a catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Show contents of a schema a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Show contents of a schema b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Show the result of a query on a table using SQL, and show the table output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Show how to create a visualisation with the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Show that we can install arbitrary Python packages , \n",
    "#  - implement visual in seaborn or matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code: get contents of a catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataOps and Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimisation (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you also have all your powerful Python visualisation libraries for building really "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Use UI to get a visual using seaborn or something like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do something interesting with the data in a really simple way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "examble_table = spark.table(\"catalog.schema.table\")\n",
    "display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions\n",
    "def load_data(data_path):\n",
    "    return None\n",
    "\n",
    "\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c352bdd64d10df8166e05e162a94d6fa8d3c84834931f5b051ebb4d3b6edf0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
