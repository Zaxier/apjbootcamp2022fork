{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo based on APJ Bootcamp flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "01 - Delta Tables.py\n",
    "\n",
    "- Load data from **Databricks Unity Catalog** Metastore\n",
    "  - What is Unity Catalog? (What are the component parts? [metastore, catalog, ... ])\n",
    "  - What is Delta Lake\n",
    "- Create a Delta Lake table based off some data made available to me from the Unity Catalog Metastore\n",
    "- Run Delta Table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've been told by my organisation that there's data available for me to start doing work on in Catalog\n",
    "\n",
    "`xaorg_dev` and what about `xaorg_prod` and `xaorg_staging`?\n",
    "\n",
    "What is in this catalog?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great I have a database here for me to work with\n",
    "Idea have a database for the sales data and a database for my personal sandbox\n",
    "\n",
    "Link to another notebook if they want to see exactly how the data got to the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What tables are in the databases?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show me the data in this table (use SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show data table and then show how easy it is to start understanding your data really quickly.\n",
    "\n",
    "- *\"Wow, you mean I can start visualising my data this easily?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe show another more complex SQL command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok now I want to manipulate my data in a more flexible way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show loading 2 tables into dataframes in PySpark, one small one big.\n",
    "- \"I can do really interesting things with datasets large and small\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tell them how their data engineers told them that they're \"updating this dataset every minute and I have access to that data set. Whoa!\"\n",
    "\n",
    "I could do a lot with this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about showing them the lineage of a data set early'ish because then we can bring up trust in the data. \n",
    "\n",
    "Where is all this data coming from? I don't trust it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show lineage\n",
    "\n",
    "Show the fact that they come from a bunch of automatic streaming jobs (DLT??) with new sales coming in every minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I really want to help out the company by reducing spend on paid juice sippers and start to use machine learning to predict the quality of our oranges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to use automl to do that by interacting with the python api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But I said I am a \"citizen data scientist\" (no one says this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most people actually want to learn. You should be hiring the people that do either way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interacting with the autoML api can be learned in a day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show my model being tracked in MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show generating predictions from the model in batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to a live real-time model inference endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Code: get contents of a catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Get contents of a schema a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Get contents of a schema b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Use UI to get a visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Use UI to get a visual using seaborn or something like that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you also have all your powerful Python visualisation libraries for building really "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code: Use UI to get a visual using seaborn or something like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do something interesting with the data in a really simple way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "examble_table = spark.table(\"catalog.schema.table\")\n",
    "display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Functions\n",
    "def load_data(data_path):\n",
    "    return None\n",
    "\n",
    "\n",
    "print('hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('default')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c352bdd64d10df8166e05e162a94d6fa8d3c84834931f5b051ebb4d3b6edf0b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
